package com.dfwy.online.sparkstreamingtask.vcloude.task;

import com.alibaba.fastjson.JSONObject;
import common.constant.Constants;
import common.pojo.applicantinformation.ApplicantInformationTO;
import common.pojo.quotas.QuotasDataValueEntity;
import common.utils.date.DateUtils;
import common.utils.exception.ErrorCodeIDE;
import common.utils.exception.ServiceException;
import common.utils.hbase.HBaseUtils;
import common.utils.md5utils.MD5Util;
import com.alibaba.fastjson.JSON;
import common.utils.stringutils.StringUtils;
import org.apache.hadoop.hbase.TableName;
import org.apache.hadoop.hbase.client.Connection;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Table;
import org.apache.hadoop.hbase.util.Bytes;


import java.util.Set;
import java.util.Vector;

import static common.constant.Constants.*;

/**
 * @author: dxx
 * @version: V-Cloude
 * @date: 2018/11/23 15:32
 * @copyright©: 2018东方微银科技（北京）有限公司
 * @file_name: TFcloude01
 * @pachage_name: online.streaming
 * @description: SparkStreaming的数据入库操作
 */
public class HBaseOperater {
    public static void data2HBase(String record, ApplicantInformationTO applicantInformationTO, String jsonStr) throws Exception {
        //获取HBase数据库连接
        Connection conn = null;
        //获取HBase表连接
        Table table = null;
        //MD5设置编码
        String charset = "UTF-8";
        try {
            conn = HBaseUtils.getCon();
            table = conn.getTable(TableName.valueOf(Constants.Dfwybank_VCloude_Hbase_BusinessJustice_TableName));
            //原始报文数据
            String amarsoftData = applicantInformationTO.getAmarsoftData();
            //ReqId
            String reqID = applicantInformationTO.getReqID();
            //BusinessID
            String businessID = applicantInformationTO.getBusinessID();
            //EntName 企业名称
            String entName = applicantInformationTO.getEntName();
            //indName	申请人姓名
            String indName = applicantInformationTO.getIndName();
            //entCreditID	社会统一信用代码
            String entCreditID = applicantInformationTO.getEntCreditID();
            //时间戳
            String yyyyMMdd = DateUtils.getUserDate("yyyyMMdd");
            //获取rowKey
            StringBuffer stringBuffer=new StringBuffer();
            String rowKey= stringBuffer.append(MD5Util.MD5Encode(businessID + reqID, charset).substring(0, 8))
                           .append("_")
                           .append(yyyyMMdd)
                           .append("_")
                           .append(businessID)
                           .append("_")
                           .append(reqID)
                           .append("_")
                           .append(entName)
                           .append("_")
                           .append(entCreditID)
                           .append("_")
                           .append(indName)
                           .toString();
            //将数据储存到Put结构之中
            Put put = new Put(Bytes.toBytes(rowKey));
            //原始数据的整体数据的储存
            put.addColumn(Bytes.toBytes(Dfwybank_VCloude_Hbase_BusinessJustice_ColumnFamily_1),
                          Bytes.toBytes(Dfwybank_VCloude_Hbase_BusinessJustice_ColumnFamily_1_ColumnName_1),
                          Bytes.toBytes(record));
            System.out.println("rowKey：" + rowKey);
            //循环向data列簇储存整个Json的KV，粗粒度储存数据
            //工商司法原始报文
            JSONObject jsonObject = JSON.parseObject(record);
            Set<String> keySet = jsonObject.keySet();
            for (String s : keySet) {
                if (StringUtils.isNotEmpty(jsonObject.getString(s))) {
                    put.addColumn(Bytes.toBytes(Dfwybank_VCloude_Hbase_BusinessJustice_ColumnFamily_1),
                            Bytes.toBytes(s), Bytes.toBytes(jsonObject.getString(s)));
                    //System.out.println("HBase数据库data:" + s + "值：" + jsonObject.getString(s));
                }
            }
            //获取amarsoftData JSONObject 并循环向info列簇储存R1103 R1104 R227等数据
            //判断列族中的数据是否为空
            if (StringUtils.isNotEmpty(jsonObject.getString("amarsoftData"))) {
                JSONObject columnNameData = jsonObject.getJSONObject("amarsoftData");

                Set<String> amarsoftDataKeySet = columnNameData.keySet();


                for (String s : amarsoftDataKeySet) {
                    if (StringUtils.isNotEmpty(columnNameData.getString(s))){
                        put.addColumn(Bytes.toBytes(Dfwybank_VCloude_Hbase_BusinessJustice_ColumnFamily_2),
                                      Bytes.toBytes(s),
                                      Bytes.toBytes(columnNameData.getString(s)));
                    }
                }
            }
            put.addColumn(Bytes.toBytes(Dfwybank_VCloude_Hbase_BusinessJustice_ColumnFamily_3),
                          Bytes.toBytes(Dfwybank_VCloude_Hbase_BusinessJustice_ColumnFamily_3_ColumnName_1),
                          Bytes.toBytes(jsonStr));
            /*for (QuotasDataValueEntity quotasDataValueEntity : dataValueList) {
                //将计算结果对象转成Json字符串，而对象成员变量为空的数据则不会出现在Json字符串中
                Object toJSON = JSONObject.toJSON(quotasDataValueEntity);
                String toJSONStr = toJSON.toString();
                JSONObject columnNameData = JSON.parseObject(toJSONStr);
                //System.out.println("columnNameData:"+columnNameData.getString("quotasName"));
                Set<String> amarsoftDataKeySet = columnNameData.keySet();
                for (String s : amarsoftDataKeySet) {
                    if (StringUtils.isNotEmpty(columnNameData.getString(s))){
                        put.addColumn(Bytes.toBytes(Dfwybank_VCloude_Hbase_BusinessJustice_ColumnFamily_3),
                                Bytes.toBytes(s),
                                Bytes.toBytes(columnNameData.getString(s)));
                    }
                }
            }*/
            //将数据存入HBase数据库
            table.put(put);
        }catch (Exception e){
            HBaseUtils.close();
            e.printStackTrace();
            throw new ServiceException(ErrorCodeIDE.VCloudeSpark.Spark_Kafka_Producer_InsertIntoHbase_ERROR
                    +"：插入HBase数据异常"
                    +System.getProperty("line.separator")
                    +e);
        }finally {
            HBaseUtils.close();
        }
    }
}
